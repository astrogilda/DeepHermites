### Hermite Networks generate smoother landscape than ReLU networks. 
(directory: lossvalues) Magnitude of loss and its variation is lower for Hermites.
(directory: betasmooth) Gradients are more stable on Hermite loss landscape as indicated by lower maximum beta smoothness. 
(directory: deltaweight)  Hermite networks have a higher effective learning rate .
(directory: sparsity): Hermite nets have higher active units than ReLU nets.
